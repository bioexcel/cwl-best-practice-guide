---
title: Writing incremental tests
sort: 4
---

# Writing incremental tests

Providing tests for workflows is important - they enable new users to be sure that a workflow behaves as expected, and also gives developers a reference to use to ensure that any changes made to the tools doesn't break the workflow. Setting up tests can be daunting, and time consuming at the start, but doing so will pay off in the long term. Below we discuss some of the details of how to do this.

## Find/create test data for each step

If the data is open then partial data from earlier steps is easiest to use.

Intermediate data for a workflow can be generated by calling the CWL reference implementation `cwl-runner` with the `--cachedir` option. This will cache all step outputs, which you can then copy to create test data for distribution. A perhaps more tedious alternative is to add workflow level `outputs` mapped from every step's outputs and copy test data manually.

The `--cachedir` option, sometimes combined with `--target` is also useful for incremental testing of a workflow, as it will reuse old outputs as long as a tool configuration and tool inputs match exactly a previous execution.Note that this means the step outputs are assumed to be reusable - for tools with mutable state (e.g. `wget` of current weather or a database lookup) add the [WorkReuse](https://www.commonwl.org/v1.2/CommandLineTool.html#WorkReuse) hint with `enableReuse: false` to force re-execution.

## Structure workflow files to support testing

CWL workflows can be [nested](https://www.commonwl.org/user_guide/22-nested-workflows/index.html). When writing a complex workflow it can be better to break this into several scripts, so that each can be tested independently.

This also allows you to make siblings of the parent workflow to tweak data handling, while retaining most of the reusable steps inside the nested workflows.


## Setting up automated testing with GitHub Actions

_TODO_

## Defensive CWL programming

_TODO_. 

Using guards for inputs and outputs

